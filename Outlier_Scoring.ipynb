{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    }
   ],
   "source": [
    "# Some standard imports for math and data handling\n",
    "import sys\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports for processing specific to this workbook\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "\n",
    "# Import the custom code developed for this work\n",
    "sys.path.append('python')\n",
    "from clusterOutliers import clusterOutliers as coo\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataScaler(qdf,nfeats=60):\n",
    "    \"\"\"\n",
    "    Data scaler for this work, returns a dataframe w/ scaled features\n",
    "    \"\"\"\n",
    "    data = qdf.iloc[:,0:nfeats]\n",
    "    scaler = preprocessing.StandardScaler().fit(data)\n",
    "    scaled_data = scaler.transform(data)\n",
    "    scaled_df = pd.DataFrame(index=qdf.index,\\\n",
    "                             columns=qdf.columns[:nfeats],\\\n",
    "                             data=scaled_data)\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_generator(suffix='_FullSample.csv',\n",
    "                     filepath=\"/home/dgiles/Documents/KeplerLCs/output/\",\n",
    "                    fits_files_directory=\"/home/dgiles/Documents/KeplerLCs/fitsFiles/\"):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        suffix (str) - the suffix of the file to be imported\n",
    "        filepath (optional, str) - filepath to the file to be imported\n",
    "        fits_files_directory (optional, str) - path to the directory containing the fits files\n",
    "        \n",
    "    Returns:\n",
    "        lambda function that with single str input of the prefix, typically a Q#.\n",
    "    \n",
    "    Use:\n",
    "        Enables simpler import of multiple quarters of data contained \n",
    "        in the same location with the same suffixes.\n",
    "    \n",
    "    Requirements: \n",
    "    import sys\n",
    "    sys.path.append('python')\n",
    "    from clusterOutliers import clusterOutliers as coo\n",
    "    \"\"\"\n",
    "    return lambda QN: coo(filepath+QN+suffix,fits_files_directory+QN+\"fitsfiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = ['Q4','Q8','Q11','Q16']\n",
    "PCA_folder = \"/home/dgiles/Documents/KeplerLCs/output/PCA_reductions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_quarter = import_generator(suffix=\"_FullSample.csv\")\n",
    "import_base = import_generator(suffix=\"_base\", filepath=PCA_folder)\n",
    "import_90 = import_generator(suffix=\"_PCA90\", filepath=PCA_folder)\n",
    "import_95 = import_generator(suffix=\"_PCA95\", filepath=PCA_folder)\n",
    "import_99 = import_generator(suffix=\"_PCA99\", filepath=PCA_folder)\n",
    "\n",
    "paper_qs = dict(zip(qs,[import_quarter(Q) for Q in qs]))\n",
    "base_qs = dict(zip(qs,[import_base(Q) for Q in qs]))\n",
    "pca90_d = dict(zip(qs,[import_90(Q) for Q in qs]))\n",
    "pca95_d = dict(zip(qs,[import_95(Q) for Q in qs]))\n",
    "pca99_d = dict(zip(qs,[import_99(Q) for Q in qs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Have to rearrange Quarter 8 data to match other data\n",
    "\"\"\"\n",
    "\n",
    "cols = base_qs['Q8'].data.columns.tolist()\n",
    "new_cols = cols[:60]+[cols[62]]+cols[60:62]+cols[63:]\n",
    "base_qs['Q8'].data = base_qs['Q8'].data[new_cols]\n",
    "\n",
    "cols = paper_qs['Q8'].data.columns.tolist()\n",
    "new_cols = cols[:60]+[cols[62]]+cols[60:62]+cols[63:]\n",
    "paper_qs['Q8'].data = paper_qs['Q8'].data[new_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dfs(PCA_folder = \"/home/dgiles/Documents/KeplerLCs/output/PCA_reductions/\"):\n",
    "    \"\"\"\n",
    "    Save function specific to this workbook.\n",
    "    \n",
    "    !!!THIS WILL OVERWRITE EXISTING FILES!!!\n",
    "    \"\"\"\n",
    "    \n",
    "    for q in pca90_d:\n",
    "        pca90_d[q].data.to_csv(PCA_folder+q+\"_PCA90\")\n",
    "    for q in pca95_d:\n",
    "        pca95_d[q].data.to_csv(PCA_folder+q+\"_PCA95\")\n",
    "    for q in pca99_d:\n",
    "        pca99_d[q].data.to_csv(PCA_folder+q+\"_PCA99\")\n",
    "    for q in base_qs:\n",
    "        base_qs['q'].data.to_csv(PCA_folder+q+\"_base\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_score(data,d2s=None,k=59):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data (Numpy array or Pandas dataframe) - Full set of data\n",
    "        d2s (Numpy array or Pandas dataframe) - Subset of data to be scored\n",
    "        k (integer) - Neighbor to which the distance is considered the score\n",
    "        \n",
    "    Returns:\n",
    "        scores (Numpy array) - MinMax scaled scores for data in d2s. \n",
    "    \"\"\"\n",
    "    # For Kepler data common to quarters 4, 8, 11, and 16, k=59 was determined to be useful.\n",
    "    if type(d2s)==None:\n",
    "        d2s=data\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree',n_jobs=-1).fit(data)\n",
    "    distances, indices = nbrs.kneighbors(d2s)\n",
    "    scores = distances[:,k]\n",
    "    scores = (scores-scores.min())/(scores.max()-scores.min()) #min max scaled\n",
    "    # TODO: readjust scaling so that the extreme outliers don't affect scores of the rest.\n",
    "    # Potentially scale 90th percentile, define all beyond that as having a score of 1.\n",
    "    \n",
    "    return list(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring the baseline (unreduced) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreLoop(qdict):\n",
    "    startTime = datetime.now()\n",
    "    scores_dict = dict()\n",
    "    for Q in adict:\n",
    "        qStartTime = datetime.now()\n",
    "        print(\"Starting {}\".format(Q))\n",
    "        QN = adict[Q]\n",
    "        data = QN.data\n",
    "        dims = 0\n",
    "        for col in data.columns:    \n",
    "            if col == 'db_out':\n",
    "                break\n",
    "            else:\n",
    "                dims+=1\n",
    "        print(\"Scoring {} in {} dimensions\".format(Q,dims))\n",
    "        scaled_data = dataScaler(data,dims)\n",
    "        out_scores = dist_score(scaled_data,scaled_data[data.db_out==-1])\n",
    "        scores_dict[Q] = out_scores\n",
    "        print(\"Time to process {}: {}\".format(Q,datetime.now()-qStartTime))\n",
    "\n",
    "    print(\"Time to process all quarters: {}\".format(datetime.now()-startTime))\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Q4\n",
      "Scoring Q4 in 60 dimensions\n",
      "Time to process Q4: 0:00:12.857038\n",
      "Starting Q8\n",
      "Scoring Q8 in 60 dimensions\n",
      "Time to process Q8: 0:00:16.674572\n",
      "Starting Q11\n",
      "Scoring Q11 in 60 dimensions\n",
      "Time to process Q11: 0:00:14.679183\n",
      "Starting Q16\n",
      "Scoring Q16 in 60 dimensions\n",
      "Time to process Q16: 0:00:16.153303\n",
      "Time to process all quarters: 0:01:00.365658\n"
     ]
    }
   ],
   "source": [
    "adict = base_qs\n",
    "base_out_scores = scoreLoop(adict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Greatest rank decrease: -161.0, kplr007742133\n",
      "Greatest rank increase: 21.0, kplr005952324\n",
      "Median difference in rank: 2.0\n",
      "Percent w/in 10: 75.0%\n",
      "Percent w/in 100: 99.87%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Q = 'Q16'\n",
    "df = base_qs[Q].data\n",
    "out_scores = base_out_scores[Q]\n",
    "out_only_comp = pd.DataFrame({\n",
    "    \"Full\":df[df.db_out==-1].dist_score.as_matrix(),\n",
    "    \"Out_only\":out_scores},\n",
    "    index=df[df.db_out==-1].index)\n",
    "out_only_comp['rank_full'] = out_only_comp.Full.rank(ascending=False)\n",
    "out_only_comp['rank_out'] = out_only_comp.Out_only.rank(ascending=False)\n",
    "rank_diffs = out_only_comp.rank_full - out_only_comp.rank_out\n",
    "print(\"\"\"\n",
    "Greatest rank decrease: {}, {}\n",
    "Greatest rank increase: {}, {}\n",
    "Median difference in rank: {}\n",
    "Percent w/in 10: {:04.1f}%\n",
    "Percent w/in 100: {:05.2f}%\n",
    "\"\"\".format(rank_diffs.min(), rank_diffs[rank_diffs==rank_diffs.min()].index[0][:13],\n",
    "          rank_diffs.max(), rank_diffs[rank_diffs==rank_diffs.max()].index[0][:13],\n",
    "          rank_diffs.median(),\n",
    "          len(rank_diffs[abs(rank_diffs)<10])/len(rank_diffs)*100,\n",
    "          len(rank_diffs[abs(rank_diffs)<100])/len(rank_diffs)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Q4\n",
      "Scoring Q4 in 18 dimensions\n",
      "Time to process Q4: 0:00:05.606169\n",
      "Starting Q8\n",
      "Scoring Q8 in 18 dimensions\n",
      "Time to process Q8: 0:00:07.081499\n",
      "Starting Q11\n",
      "Scoring Q11 in 17 dimensions\n",
      "Time to process Q11: 0:00:08.167452\n",
      "Starting Q16\n",
      "Scoring Q16 in 17 dimensions\n",
      "Time to process Q16: 0:00:05.555375\n",
      "Time to process all quarters: 0:00:26.412719\n"
     ]
    }
   ],
   "source": [
    "adict = pca90_d\n",
    "pca90_out_scores = scoreLoop(adict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Greatest rank decrease: -181.0, kplr009821923\n",
      "Greatest rank increase: 18.0, kplr002019352\n",
      "Median difference in rank: 2.0\n",
      "Percent w/in 10: 78.8%\n",
      "Percent w/in 100: 99.91%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Q = 'Q16'\n",
    "df = pca90_d[Q].data\n",
    "out_scores = pca90_out_scores[Q]\n",
    "out_only_comp = pd.DataFrame({\n",
    "    \"Full\":df[df.db_out==-1].dist_score.as_matrix(),\n",
    "    \"Out_only\":out_scores},\n",
    "    index=df[df.db_out==-1].index)\n",
    "out_only_comp['rank_full'] = out_only_comp.Full.rank(ascending=False)\n",
    "out_only_comp['rank_out'] = out_only_comp.Out_only.rank(ascending=False)\n",
    "rank_diffs = out_only_comp.rank_full - out_only_comp.rank_out\n",
    "print(\"\"\"\n",
    "Greatest rank decrease: {}, {}\n",
    "Greatest rank increase: {}, {}\n",
    "Median difference in rank: {}\n",
    "Percent w/in 10: {:04.1f}%\n",
    "Percent w/in 100: {:05.2f}%\n",
    "\"\"\".format(rank_diffs.min(), rank_diffs[rank_diffs==rank_diffs.min()].index[0][:13],\n",
    "          rank_diffs.max(), rank_diffs[rank_diffs==rank_diffs.max()].index[0][:13],\n",
    "          rank_diffs.median(),\n",
    "          len(rank_diffs[abs(rank_diffs)<10])/len(rank_diffs)*100,\n",
    "          len(rank_diffs[abs(rank_diffs)<100])/len(rank_diffs)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Q4\n",
      "Scoring Q4 in 23 dimensions\n",
      "Time to process Q4: 0:00:09.120561\n",
      "Starting Q8\n",
      "Scoring Q8 in 24 dimensions\n",
      "Time to process Q8: 0:00:08.660059\n",
      "Starting Q11\n",
      "Scoring Q11 in 22 dimensions\n",
      "Time to process Q11: 0:00:06.728444\n",
      "Starting Q16\n",
      "Scoring Q16 in 23 dimensions\n",
      "Time to process Q16: 0:00:06.948755\n",
      "Time to process all quarters: 0:00:31.459481\n"
     ]
    }
   ],
   "source": [
    "adict = pca95_d\n",
    "pca95_out_scores = scoreLoop(adict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Greatest rank decrease: -116.0, kplr001873918\n",
      "Greatest rank increase: 15.0, kplr005630212\n",
      "Median difference in rank: 2.0\n",
      "Percent w/in 10: 84.2%\n",
      "Percent w/in 100: 99.91%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Q = 'Q16'\n",
    "df = pca95_d[Q].data\n",
    "out_scores = pca95_out_scores[Q]\n",
    "out_only_comp = pd.DataFrame({\n",
    "    \"Full\":df[df.db_out==-1].dist_score.as_matrix(),\n",
    "    \"Out_only\":out_scores},\n",
    "    index=df[df.db_out==-1].index)\n",
    "out_only_comp['rank_full'] = out_only_comp.Full.rank(ascending=False)\n",
    "out_only_comp['rank_out'] = out_only_comp.Out_only.rank(ascending=False)\n",
    "rank_diffs = out_only_comp.rank_full - out_only_comp.rank_out\n",
    "print(\"\"\"\n",
    "Greatest rank decrease: {}, {}\n",
    "Greatest rank increase: {}, {}\n",
    "Median difference in rank: {}\n",
    "Percent w/in 10: {:04.1f}%\n",
    "Percent w/in 100: {:05.2f}%\n",
    "\"\"\".format(rank_diffs.min(), rank_diffs[rank_diffs==rank_diffs.min()].index[0][:13],\n",
    "          rank_diffs.max(), rank_diffs[rank_diffs==rank_diffs.max()].index[0][:13],\n",
    "          rank_diffs.median(),\n",
    "          len(rank_diffs[abs(rank_diffs)<10])/len(rank_diffs)*100,\n",
    "          len(rank_diffs[abs(rank_diffs)<100])/len(rank_diffs)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Q4\n",
      "Scoring Q4 in 35 dimensions\n",
      "Time to process Q4: 0:00:10.271810\n",
      "Starting Q8\n",
      "Scoring Q8 in 36 dimensions\n",
      "Time to process Q8: 0:00:11.830123\n",
      "Starting Q11\n",
      "Scoring Q11 in 34 dimensions\n",
      "Time to process Q11: 0:00:12.934743\n",
      "Starting Q16\n",
      "Scoring Q16 in 34 dimensions\n",
      "Time to process Q16: 0:00:12.732713\n",
      "Time to process all quarters: 0:00:47.770770\n"
     ]
    }
   ],
   "source": [
    "adict = pca99_d\n",
    "pca99_out_scores = scoreLoop(adict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Greatest rank decrease: -104.0, kplr005451040\n",
      "Greatest rank increase: 17.0, kplr001849235\n",
      "Median difference in rank: 2.0\n",
      "Percent w/in 10: 88.7%\n",
      "Percent w/in 100: 99.98%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Q = 'Q16'\n",
    "df = pca99_d[Q].data\n",
    "out_scores = pca99_out_scores[Q]\n",
    "out_only_comp = pd.DataFrame({\n",
    "    \"Full\":df[df.db_out==-1].dist_score.as_matrix(),\n",
    "    \"Out_only\":out_scores},\n",
    "    index=df[df.db_out==-1].index)\n",
    "out_only_comp['rank_full'] = out_only_comp.Full.rank(ascending=False)\n",
    "out_only_comp['rank_out'] = out_only_comp.Out_only.rank(ascending=False)\n",
    "rank_diffs = out_only_comp.rank_full - out_only_comp.rank_out\n",
    "print(\"\"\"\n",
    "Greatest rank decrease: {}, {}\n",
    "Greatest rank increase: {}, {}\n",
    "Median difference in rank: {}\n",
    "Percent w/in 10: {:04.1f}%\n",
    "Percent w/in 100: {:05.2f}%\n",
    "\"\"\".format(rank_diffs.min(), rank_diffs[rank_diffs==rank_diffs.min()].index[0][:13],\n",
    "          rank_diffs.max(), rank_diffs[rank_diffs==rank_diffs.max()].index[0][:13],\n",
    "          rank_diffs.median(),\n",
    "          len(rank_diffs[abs(rank_diffs)<10])/len(rank_diffs)*100,\n",
    "          len(rank_diffs[abs(rank_diffs)<100])/len(rank_diffs)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
