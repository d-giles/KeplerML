{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook seeks to explore the utility of dimensionality reduction with PCA prior to clustering. At the time of this writing, this notebook considers 3 levels of variance explained: 90%, 95%, and 99%. \n",
    "Aside from the reduction we will process the data in the same way as previously done. We will scale the data using sklearn's standardScaler and cluster the data using the method clusterOutliers.db_out.\n",
    "We will compare these reductions to the clustering done on the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some standard imports for math and data handling\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Imports for processing specific to this workbook\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "\n",
    "# Import the custom code developed for this work\n",
    "import sys\n",
    "sys.path.append('python')\n",
    "from clusterOutliers import clusterOutliers as coo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_quarter(QN='Q4'):\n",
    "    # Import the dataframe containing the data\n",
    "    featCSV = \"/home/dgiles/Documents/KeplerLCs/output/\"+QN+\"_FullSample.csv\" # Path to csv containing feature data (should be a pandas dataframe saved as a csv)\n",
    "    fitsDir = \"/home/dgiles/Documents/KeplerLCs/fitsFiles/\"+QN+\"fitsfiles\" # path to fits files folder\n",
    "    return coo(featCSV,fitsDir)\n",
    "\n",
    "Q4 = import_quarter('Q4')\n",
    "Q8 = import_quarter('Q8')\n",
    "Q11 = import_quarter('Q11')\n",
    "Q16 = import_quarter('Q16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['db_out', 'pca_x', 'pca_y', 'db_cluster', 'exc_labels'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check what's in the data\n",
    "print(Q4.data.columns[60:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* db_out - cluster designation made earlier by this work (based on DBSCAN, but focused on outliers. Only has 3 designations.)\n",
    "* pca_x - 1st dimension of a 2D PCA reduction\n",
    "* pca_y - 2nd dimension of a 2D PCA reduction\n",
    "* db_cluster - Actual DBSCAN cluster identifier\n",
    "* exc_labels - Labels for each object as to whether they are outliers in a single quarter, multiple quarters, or all quarters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataScaler(qdf):\n",
    "    \"\"\"\n",
    "    Data scaler for this work, returns a dataframe w/ scaled features\n",
    "    \"\"\"\n",
    "    data = qdf.iloc[:,0:60]\n",
    "    scaler = preprocessing.StandardScaler().fit(data)\n",
    "    scaled_data = scaler.transform(data)\n",
    "    scaled_df = pd.DataFrame(index=qdf.index,\\\n",
    "                             columns=qdf.columns[:60],\\\n",
    "                             data=scaled_data)\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca_red(data,scaled=False,var_rat=0.9):\n",
    "    \"\"\"\n",
    "    Returns a pca reduction of the given data that explains a\n",
    "    given fraction of the variance.\n",
    "    Args:\n",
    "        data (pandas dataframe) - the data to be reduced\n",
    "        var_rat (float between 0 and 1) - the ratio of variance to be \n",
    "            explained by the transformed data\n",
    "            \n",
    "    Returns:\n",
    "        reduced_data - numpy array of reduced data\n",
    "        prints the number of dimensions and the explained variance\n",
    "    \"\"\"\n",
    "    if scaled:\n",
    "        scaled_data = data\n",
    "    else:\n",
    "        print(\"Scaling data using StandardScaler...\")\n",
    "        scaled_data = dataScaler(data)\n",
    "\n",
    "    print(\"Finding minimum number of dimensions to explain {:04.1f}% of the variance...\".format(var_rat*100))\n",
    "    \n",
    "    for i in range(60):\n",
    "        pca = PCA(n_components=i)\n",
    "        pca.fit(scaled_data)\n",
    "        if sum(pca.explained_variance_ratio_) >= var_rat:\n",
    "            break\n",
    "    print(\"\"\"\n",
    "    Dimensions: {:d},\n",
    "    Variance explained: {:04.1f}%\n",
    "    \"\"\".format(i,sum(pca.explained_variance_ratio_)*100))\n",
    "    reduced_data = pd.DataFrame(index=data.index, \\\n",
    "                                data=pca.transform(scaled_data))\n",
    "    return reduced_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reductions and Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quarter 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Reduction explaining 90% of the variance:\n",
      "Scaling data using StandardScaler...\n",
      "Finding minimum number of dimensions to explain 90.0% of the variance...\n",
      "\n",
      "    Dimensions: 18,\n",
      "    Variance explained: 90.5%\n",
      "    \n",
      "Time to reduce: 0:00:13.124157\n",
      "PCA Reduction explaining 95% of the variance:\n",
      "Scaling data using StandardScaler...\n",
      "Finding minimum number of dimensions to explain 95.0% of the variance...\n",
      "\n",
      "    Dimensions: 23,\n",
      "    Variance explained: 95.1%\n",
      "    \n",
      "Time to reduce: 0:00:19.107702\n",
      "PCA Reduction explaining 99% of the variance:\n",
      "Scaling data using StandardScaler...\n",
      "Finding minimum number of dimensions to explain 99.0% of the variance...\n",
      "\n",
      "    Dimensions: 35,\n",
      "    Variance explained: 99.1%\n",
      "    \n",
      "Time to reduce: 0:00:39.758400\n"
     ]
    }
   ],
   "source": [
    "# Only want to scale the feature data generated by keplerml.py\n",
    "data_tbs = Q4.data.iloc[:,0:60]\n",
    "reds = dict()\n",
    "for i,vr in enumerate([0.9,0.95,0.99]):\n",
    "    print(\"PCA Reduction explaining {:02.0f}% of the variance:\".format(vr*100))\n",
    "    start = datetime.now()\n",
    "    reds[i] = pca_red(data_tbs, var_rat=vr)\n",
    "    print(\"Time to reduce: {}\".format(datetime.now()-start))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating Parameters...\n",
      "Sampling data for parameter estimation...\n",
      "Calculating nearest neighbor distances...\n",
      "Finding elbow...\n",
      "\n",
      "        Epsilon is in the neighborhood of 04.04.\n",
      "        \n",
      "Scaling density...\n",
      "Clustering data with DBSCAN, eps=04.04,min_samples=59.9156...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgiles/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:131: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "python/db_outliers.py:112: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  distArr = distances[:,min_n]    #this should be calculated before eps_est and fed in, it's\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 2 clusters and 3216 total outliers\n",
      "Time to cluster: 0:05:05.053670\n",
      "Estimating Parameters...\n",
      "Sampling data for parameter estimation...\n",
      "Calculating nearest neighbor distances...\n",
      "Finding elbow...\n",
      "\n",
      "        Epsilon is in the neighborhood of 03.83.\n",
      "        \n",
      "Scaling density...\n",
      "Clustering data with DBSCAN, eps=03.83,min_samples=59.9156...\n",
      "There were 2 clusters and 4203 total outliers\n",
      "Time to cluster: 0:05:09.315667\n",
      "Estimating Parameters...\n",
      "Sampling data for parameter estimation...\n",
      "Calculating nearest neighbor distances...\n",
      "Finding elbow...\n",
      "\n",
      "        Epsilon is in the neighborhood of 05.13.\n",
      "        \n",
      "Scaling density...\n",
      "Clustering data with DBSCAN, eps=05.13,min_samples=59.9156...\n",
      "There were 2 clusters and 3203 total outliers\n",
      "Time to cluster: 0:07:33.823373\n"
     ]
    }
   ],
   "source": [
    "for k in reds:\n",
    "    start = datetime.now()\n",
    "    out_labels = Q4.db_out(df=reds[k])\n",
    "    reds[k]['db_out']=out_labels\n",
    "    print(\"Time to cluster: {}\".format(datetime.now()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PCA_folder = \"/home/dgiles/Documents/KeplerLCs/output/PCA_reductions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reds[0].to_csv(PCA_folder+\"Q4_PCA90\")\n",
    "reds[1].to_csv(PCA_folder+\"Q4_PCA95\")\n",
    "reds[2].to_csv(PCA_folder+\"Q4_PCA99\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "QN=\"Q4\"\n",
    "fitsDir = \"/home/dgiles/Documents/KeplerLCs/fitsFiles/\"+QN+\"fitsfiles\"\n",
    "Q4_pca90 = coo(feats=PCA_folder+QN+\"_PCA90\",fitsDir=fitsDir)\n",
    "Q4_pca95 = coo(feats=PCA_folder+QN+\"_PCA95\",fitsDir=fitsDir)\n",
    "Q4_pca99 = coo(feats=PCA_folder+QN+\"_PCA99\",fitsDir=fitsDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quarter 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Reduction explaining 90% of the variance:\n",
      "Scaling data using StandardScaler...\n",
      "Finding minimum number of dimensions to explain 90.0% of the variance...\n",
      "\n",
      "    Dimensions: 18,\n",
      "    Variance explained: 90.7%\n",
      "    \n",
      "Time to reduce: 0:00:14.487903\n",
      "\n",
      "Estimating Parameters...\n",
      "Sampling data for parameter estimation...\n",
      "Calculating nearest neighbor distances...\n",
      "Finding elbow...\n",
      "\n",
      "        Epsilon is in the neighborhood of 04.07.\n",
      "        \n",
      "Scaling density...\n",
      "Clustering data with DBSCAN, eps=04.07,min_samples=59.9156...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgiles/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:131: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "python/db_outliers.py:112: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  distArr = distances[:,min_n]    #this should be calculated before eps_est and fed in, it's\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 2 clusters and 3475 total outliers\n",
      "Time to cluster: 0:05:40.626828\n",
      "    Total time to process: 0:05:55.115283\n",
      "\n",
      "PCA Reduction explaining 95% of the variance:\n",
      "Scaling data using StandardScaler...\n",
      "Finding minimum number of dimensions to explain 95.0% of the variance...\n",
      "\n",
      "    Dimensions: 24,\n",
      "    Variance explained: 95.4%\n",
      "    \n",
      "Time to reduce: 0:00:21.812244\n",
      "\n",
      "Estimating Parameters...\n",
      "Sampling data for parameter estimation...\n",
      "Calculating nearest neighbor distances...\n",
      "Finding elbow...\n",
      "\n",
      "        Epsilon is in the neighborhood of 04.46.\n",
      "        \n",
      "Scaling density...\n",
      "Clustering data with DBSCAN, eps=04.46,min_samples=59.9156...\n",
      "There were 2 clusters and 3658 total outliers\n",
      "Time to cluster: 0:06:48.035085\n",
      "    Total time to process: 0:07:09.847866\n",
      "\n",
      "PCA Reduction explaining 99% of the variance:\n",
      "Scaling data using StandardScaler...\n",
      "Finding minimum number of dimensions to explain 99.0% of the variance...\n",
      "\n",
      "    Dimensions: 36,\n",
      "    Variance explained: 99.1%\n",
      "    \n",
      "Time to reduce: 0:00:40.486147\n",
      "\n",
      "Estimating Parameters...\n",
      "Sampling data for parameter estimation...\n",
      "Calculating nearest neighbor distances...\n",
      "Finding elbow...\n",
      "\n",
      "        Epsilon is in the neighborhood of 05.24.\n",
      "        \n",
      "Scaling density...\n",
      "Clustering data with DBSCAN, eps=05.24,min_samples=59.9156...\n",
      "There were 2 clusters and 3327 total outliers\n",
      "Time to cluster: 0:07:45.262471\n",
      "    Total time to process: 0:08:25.749158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Only want to scale the feature data generated by keplerml.py\n",
    "data_tbs = Q8.data.iloc[:,0:60]\n",
    "reds = dict()\n",
    "for i,vr in enumerate([0.9,0.95,0.99]):\n",
    "    print(\"PCA Reduction explaining {:02.0f}% of the variance:\".format(vr*100))\n",
    "    rstart = datetime.now()\n",
    "    reds[i] = pca_red(data_tbs, var_rat=vr)\n",
    "    print(\"Time to reduce: {}\".format(datetime.now()-rstart))\n",
    "    print(\"\")\n",
    "    cstart = datetime.now()\n",
    "    # it doesn't matter which cluster object calls the \n",
    "    # method since the data frame to be processed is provided explicitly\n",
    "    out_labels = Q4.db_out(df=reds[i]) \n",
    "    reds[i]['db_out']=out_labels\n",
    "    print(\"\"\"Time to cluster: {}\n",
    "    Total time to process: {}\"\"\".format(datetime.now()-cstart,datetime.now()-rstart))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reds[0].to_csv(PCA_folder+\"Q8_PCA90\")\n",
    "reds[1].to_csv(PCA_folder+\"Q8_PCA95\")\n",
    "reds[2].to_csv(PCA_folder+\"Q8_PCA99\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QN=\"Q8\"\n",
    "fitsDir = \"/home/dgiles/Documents/KeplerLCs/fitsFiles/\"+QN+\"fitsfiles\"\n",
    "Q8_pca90 = coo(feats=PCA_folder+QN+\"_PCA90\",fitsDir=fitsDir)\n",
    "Q8_pca95 = coo(feats=PCA_folder+QN+\"_PCA95\",fitsDir=fitsDir)\n",
    "Q8_pca99 = coo(feats=PCA_folder+QN+\"_PCA99\",fitsDir=fitsDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quarter 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Reduction explaining 90% of the variance:\n",
      "Scaling data using StandardScaler...\n",
      "Finding minimum number of dimensions to explain 90.0% of the variance...\n",
      "\n",
      "    Dimensions: 17,\n",
      "    Variance explained: 90.8%\n",
      "    \n",
      "Time to reduce: 0:00:13.315329\n",
      "\n",
      "Estimating Parameters...\n",
      "Sampling data for parameter estimation...\n",
      "Calculating nearest neighbor distances...\n",
      "Finding elbow...\n",
      "\n",
      "        Epsilon is in the neighborhood of 03.14.\n",
      "        \n",
      "Scaling density...\n",
      "Clustering data with DBSCAN, eps=03.14,min_samples=59.9156...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgiles/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:131: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "python/db_outliers.py:112: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  distArr = distances[:,min_n]    #this should be calculated before eps_est and fed in, it's\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 2 clusters and 4712 total outliers\n",
      "Time to cluster: 0:05:45.844997\n",
      "    Total time to process: 0:05:59.160851\n",
      "\n",
      "PCA Reduction explaining 95% of the variance:\n",
      "Scaling data using StandardScaler...\n",
      "Finding minimum number of dimensions to explain 95.0% of the variance...\n",
      "\n",
      "    Dimensions: 22,\n",
      "    Variance explained: 95.1%\n",
      "    \n",
      "Time to reduce: 0:00:19.301998\n",
      "\n",
      "Estimating Parameters...\n",
      "Sampling data for parameter estimation...\n",
      "Calculating nearest neighbor distances...\n",
      "Finding elbow...\n",
      "\n",
      "        Epsilon is in the neighborhood of 04.63.\n",
      "        \n",
      "Scaling density...\n",
      "Clustering data with DBSCAN, eps=04.63,min_samples=59.9156...\n",
      "There were 2 clusters and 3217 total outliers\n",
      "Time to cluster: 0:06:34.340393\n",
      "    Total time to process: 0:06:53.643074\n",
      "\n",
      "PCA Reduction explaining 99% of the variance:\n",
      "Scaling data using StandardScaler...\n",
      "Finding minimum number of dimensions to explain 99.0% of the variance...\n",
      "\n",
      "    Dimensions: 34,\n",
      "    Variance explained: 99.1%\n",
      "    \n",
      "Time to reduce: 0:00:38.415011\n",
      "\n",
      "Estimating Parameters...\n",
      "Sampling data for parameter estimation...\n",
      "Calculating nearest neighbor distances...\n",
      "Finding elbow...\n",
      "\n",
      "        Epsilon is in the neighborhood of 05.27.\n",
      "        \n",
      "Scaling density...\n",
      "Clustering data with DBSCAN, eps=05.27,min_samples=59.9156...\n",
      "There were 2 clusters and 3074 total outliers\n",
      "Time to cluster: 0:08:31.832725\n",
      "    Total time to process: 0:09:10.247935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Only want to scale the feature data generated by keplerml.py\n",
    "data_tbs = Q11.data.iloc[:,0:60]\n",
    "reds = dict()\n",
    "for i,vr in enumerate([0.9,0.95,0.99]):\n",
    "    print(\"PCA Reduction explaining {:02.0f}% of the variance:\".format(vr*100))\n",
    "    rstart = datetime.now()\n",
    "    reds[i] = pca_red(data_tbs, var_rat=vr)\n",
    "    print(\"Time to reduce: {}\".format(datetime.now()-rstart))\n",
    "    print(\"\")\n",
    "    cstart = datetime.now()\n",
    "    # it doesn't matter which cluster object calls the \n",
    "    # method since the data frame to be processed is provided explicitly\n",
    "    out_labels = Q4.db_out(df=reds[i]) \n",
    "    reds[i]['db_out']=out_labels\n",
    "    print(\"\"\"Time to cluster: {}\n",
    "    Total time to process: {}\"\"\".format(datetime.now()-cstart,datetime.now()-rstart))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reds[0].to_csv(PCA_folder+\"Q11_PCA90\")\n",
    "reds[1].to_csv(PCA_folder+\"Q11_PCA95\")\n",
    "reds[2].to_csv(PCA_folder+\"Q11_PCA99\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QN=\"Q11\"\n",
    "fitsDir = \"/home/dgiles/Documents/KeplerLCs/fitsFiles/\"+QN+\"fitsfiles\"\n",
    "Q11_pca90 = coo(feats=PCA_folder+QN+\"_PCA90\",fitsDir=fitsDir)\n",
    "Q11_pca95 = coo(feats=PCA_folder+QN+\"_PCA95\",fitsDir=fitsDir)\n",
    "Q11_pca99 = coo(feats=PCA_folder+QN+\"_PCA99\",fitsDir=fitsDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quarter 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Reduction explaining 90% of the variance:\n",
      "Scaling data using StandardScaler...\n",
      "Finding minimum number of dimensions to explain 90.0% of the variance...\n",
      "\n",
      "    Dimensions: 17,\n",
      "    Variance explained: 90.1%\n",
      "    \n",
      "Time to reduce: 0:00:13.144180\n",
      "\n",
      "Estimating Parameters...\n",
      "Sampling data for parameter estimation...\n",
      "Calculating nearest neighbor distances...\n",
      "Finding elbow...\n",
      "\n",
      "        Epsilon is in the neighborhood of 03.92.\n",
      "        \n",
      "Scaling density...\n",
      "Clustering data with DBSCAN, eps=03.92,min_samples=59.9156...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgiles/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:131: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "python/db_outliers.py:112: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  distArr = distances[:,min_n]    #this should be calculated before eps_est and fed in, it's\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 2 clusters and 3526 total outliers\n",
      "Time to cluster: 0:06:31.139474\n",
      "    Total time to process: 0:06:44.284192\n",
      "\n",
      "PCA Reduction explaining 95% of the variance:\n",
      "Scaling data using StandardScaler...\n",
      "Finding minimum number of dimensions to explain 95.0% of the variance...\n",
      "\n",
      "    Dimensions: 23,\n",
      "    Variance explained: 95.6%\n",
      "    \n",
      "Time to reduce: 0:00:21.149542\n",
      "\n",
      "Estimating Parameters...\n",
      "Sampling data for parameter estimation...\n",
      "Calculating nearest neighbor distances...\n",
      "Finding elbow...\n",
      "\n",
      "        Epsilon is in the neighborhood of 04.50.\n",
      "        \n",
      "Scaling density...\n",
      "Clustering data with DBSCAN, eps=04.50,min_samples=59.9156...\n",
      "There were 2 clusters and 3484 total outliers\n",
      "Time to cluster: 0:06:04.522204\n",
      "    Total time to process: 0:06:25.672290\n",
      "\n",
      "PCA Reduction explaining 99% of the variance:\n",
      "Scaling data using StandardScaler...\n",
      "Finding minimum number of dimensions to explain 99.0% of the variance...\n",
      "\n",
      "    Dimensions: 34,\n",
      "    Variance explained: 99.0%\n",
      "    \n",
      "Time to reduce: 0:00:36.888205\n",
      "\n",
      "Estimating Parameters...\n",
      "Sampling data for parameter estimation...\n",
      "Calculating nearest neighbor distances...\n",
      "Finding elbow...\n",
      "\n",
      "        Epsilon is in the neighborhood of 04.52.\n",
      "        \n",
      "Scaling density...\n",
      "Clustering data with DBSCAN, eps=04.52,min_samples=59.9156...\n",
      "There were 2 clusters and 4037 total outliers\n",
      "Time to cluster: 0:06:42.448290\n",
      "    Total time to process: 0:07:19.336811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Only want to scale the feature data generated by keplerml.py\n",
    "data_tbs = Q16.data.iloc[:,0:60]\n",
    "reds = dict()\n",
    "for i,vr in enumerate([0.9,0.95,0.99]):\n",
    "    print(\"PCA Reduction explaining {:02.0f}% of the variance:\".format(vr*100))\n",
    "    rstart = datetime.now()\n",
    "    reds[i] = pca_red(data_tbs, var_rat=vr)\n",
    "    print(\"Time to reduce: {}\".format(datetime.now()-rstart))\n",
    "    print(\"\")\n",
    "    cstart = datetime.now()\n",
    "    # it doesn't matter which cluster object calls the \n",
    "    # method since the data frame to be processed is provided explicitly\n",
    "    out_labels = Q4.db_out(df=reds[i]) \n",
    "    reds[i]['db_out']=out_labels\n",
    "    print(\"\"\"Time to cluster: {}\n",
    "    Total time to process: {}\"\"\".format(datetime.now()-cstart,datetime.now()-rstart))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reds[0].to_csv(PCA_folder+\"Q16_PCA90\")\n",
    "reds[1].to_csv(PCA_folder+\"Q16_PCA95\")\n",
    "reds[2].to_csv(PCA_folder+\"Q16_PCA99\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QN=\"Q16\"\n",
    "fitsDir = \"/home/dgiles/Documents/KeplerLCs/fitsFiles/\"+QN+\"fitsfiles\"\n",
    "Q16_pca90 = coo(feats=PCA_folder+QN+\"_PCA90\",fitsDir=fitsDir)\n",
    "Q16_pca95 = coo(feats=PCA_folder+QN+\"_PCA95\",fitsDir=fitsDir)\n",
    "Q16_pca99 = coo(feats=PCA_folder+QN+\"_PCA99\",fitsDir=fitsDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating Parameters...\n",
      "Sampling data for parameter estimation...\n",
      "Calculating nearest neighbor distances...\n",
      "Finding elbow...\n",
      "\n",
      "        Epsilon is in the neighborhood of 05.36.\n",
      "        \n",
      "Scaling density...\n",
      "Clustering data with DBSCAN, eps=05.36,min_samples=59.9156...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgiles/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:131: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "python/db_outliers.py:112: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  distArr = distances[:,min_n]    #this should be calculated before eps_est and fed in, it's\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 2 clusters and 3098 total outliers\n",
      "Time to cluster: 0:13:06.068176\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "scaled_data = dataScaler(Q4.data)\n",
    "Q4_base = Q4.db_out(df=scaled_data)\n",
    "print(\"Time to cluster: {}\".format(datetime.now()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter 8 baseline\n"
     ]
    }
   ],
   "source": [
    "print(\"Quarter 8 baseline\")\n",
    "start = datetime.now()\n",
    "scaled_data = dataScaler(Q8.data)\n",
    "Q8_base = Q8.db_out(df=scaled_data)\n",
    "print(\"Time to cluster: {}\".format(datetime.now()-start))\n",
    "\n",
    "print(\"Quarter 11 baseline\")\n",
    "start = datetime.now()\n",
    "scaled_data = dataScaler(Q11.data)\n",
    "Q11_base = Q11.db_out(df=scaled_data)\n",
    "print(\"Time to cluster: {}\".format(datetime.now()-start))\n",
    "\n",
    "print(\"Quarter 16 baseline\")\n",
    "start = datetime.now()\n",
    "scaled_data = dataScaler(Q16.data)\n",
    "Q16_base = Q16.db_out(df=scaled_data)\n",
    "print(\"Time to cluster: {}\".format(datetime.now()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q4 Total Outliers: 3098\n",
      "Q8 Total Outliers: 4123\n",
      "Q11 Total Outliers: 3151\n",
      "Q16 Total Outliers: 4796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Q4 Total Outliers: {:d}\n",
    "Q8 Total Outliers: {:d}\n",
    "Q11 Total Outliers: {:d}\n",
    "Q16 Total Outliers: {:d}\n",
    "\"\"\".format(len(Q4_base[Q4_base==-1]),\n",
    "           len(Q8_base[Q8_base==-1]),\n",
    "           len(Q11_base[Q11_base==-1]),\n",
    "           len(Q16_base[Q16_base==-1])\n",
    "          )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The clusterOutlier objects bring in previously calculated cluster designations\n",
    "# We have redone the clustering here in the interest of ensuring we apply\n",
    "# the same methodology throughout.\n",
    "# So we store the newly produced cluster output in 'b' versions.\n",
    "# I don't know if this is working the way I intend it to...\n",
    "Q4b = Q4\n",
    "Q4b.data['db_out']=Q4_base\n",
    "Q8b = Q8\n",
    "Q8b.data['db_out']=Q8_base\n",
    "Q11b = Q11\n",
    "Q11b.data['db_out']=Q11_base\n",
    "Q16b = Q16\n",
    "Q16b.data['db_out']=Q16_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Population Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Outliers In Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kid_out = lambda q: q.data.index[q.data.db_out==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q4outs = kid_out(Q4)\n",
    "q490outs = kid_out(Q4_pca90)\n",
    "q495outs = kid_out(Q4_pca95)\n",
    "q499outs = kid_out(Q4_pca99)\n",
    "\n",
    "q8outs = kid_out(Q8)\n",
    "q890outs = kid_out(Q8_pca90)\n",
    "q895outs = kid_out(Q8_pca95)\n",
    "q899outs = kid_out(Q8_pca99)\n",
    "\n",
    "q11outs = kid_out(Q11)\n",
    "q1190outs = kid_out(Q11_pca90)\n",
    "q1195outs = kid_out(Q11_pca95)\n",
    "q1199outs = kid_out(Q11_pca99)\n",
    "\n",
    "q16outs = kid_out(Q16)\n",
    "q1690outs = kid_out(Q16_pca90)\n",
    "q1695outs = kid_out(Q16_pca95)\n",
    "q1699outs = kid_out(Q16_pca99)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 90% to Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in common, quarter 4: 2958\n",
      "Outliers in common, quarter 8: 3452\n",
      "Outliers in common, quarter 11: 3140\n",
      "Outliers in common, quarter 16: 3526\n"
     ]
    }
   ],
   "source": [
    "q4comm = np.intersect1d(q4outs,q4pca90outs)\n",
    "print(\"Outliers in common, quarter 4: {:d}\".format(len(q4comm)))\n",
    "q8comm = np.intersect1d(q8outs,q890outs)\n",
    "print(\"Outliers in common, quarter 8: {:d}\".format(len(q8comm)))\n",
    "q11comm = np.intersect1d(q11outs,q1190outs)\n",
    "print(\"Outliers in common, quarter 11: {:d}\".format(len(q11comm)))\n",
    "q16comm = np.intersect1d(q16outs,q1690outs)\n",
    "print(\"Outliers in common, quarter 16: {:d}\".format(len(q16comm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 95% to Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in common, quarter 4: 3085\n",
      "Outliers in common, quarter 8: 3653\n",
      "Outliers in common, quarter 11: 3066\n",
      "Outliers in common, quarter 16: 3484\n"
     ]
    }
   ],
   "source": [
    "q4comm = np.intersect1d(q4outs,q495outs)\n",
    "print(\"Outliers in common, quarter 4: {:d}\".format(len(q4comm)))\n",
    "q8comm = np.intersect1d(q8outs,q895outs)\n",
    "print(\"Outliers in common, quarter 8: {:d}\".format(len(q8comm)))\n",
    "q11comm = np.intersect1d(q11outs,q1195outs)\n",
    "print(\"Outliers in common, quarter 11: {:d}\".format(len(q11comm)))\n",
    "q16comm = np.intersect1d(q16outs,q1695outs)\n",
    "print(\"Outliers in common, quarter 16: {:d}\".format(len(q16comm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 99% to Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in common, quarter 4: 3075\n",
      "Outliers in common, quarter 8: 3327\n",
      "Outliers in common, quarter 11: 3071\n",
      "Outliers in common, quarter 16: 4037\n"
     ]
    }
   ],
   "source": [
    "q4comm = np.intersect1d(q4outs,q499outs)\n",
    "print(\"Outliers in common, quarter 4: {:d}\".format(len(q4comm)))\n",
    "q8comm = np.intersect1d(q8outs,q899outs)\n",
    "print(\"Outliers in common, quarter 8: {:d}\".format(len(q8comm)))\n",
    "q11comm = np.intersect1d(q11outs,q1199outs)\n",
    "print(\"Outliers in common, quarter 11: {:d}\".format(len(q11comm)))\n",
    "q16comm = np.intersect1d(q16outs,q1699outs)\n",
    "print(\"Outliers in common, quarter 16: {:d}\".format(len(q16comm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in common: 3526\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
