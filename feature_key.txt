#Author: Lucianne Walkowicz, from code written by Revant Nayar
#This file contains a list of the features calculated in the order in which they appear in the output file "allparameters.txt". 
#Code snippets are shown currently, with the intent of turning these into written descriptions of each feature. 
#Code snippets are not intended to work out of the box and are shown for illustration purposes only. 

1. Revantese to English translations

numpdc - this is the PDC_SAP_FLUX array cleaned of NaNs. By analogy, numtime and numerr are the time and error arrays of same, also cleaned of NaNs

the index "i" refers to the index in the entire array of lightcurve files, i.e. "i" goes from 0 to 160000+. I have taken i out whereever it occurs as the calculations for an individual lightcurve are now within a loop that loops over i, rather than every single calculation looping over i (facepalm).

longtermtrend and yoffset - he did a linear fit to the entire lightcurve to capture overall slope, if any-- longtermtrend is the slope of this linear fit, yoffset is the intercept

corrpdc - this is some crazy ass version of normalizing the lightcurve, where he divided off the linear trend computed above from the entire lightcurve. In the rewrite I normalized the flux by the median to begin with, so I've used "nf" (the normalize flux in place of both numpdc and corrpdc. Hopefully that will be ok.  

Features:

1  longtermtrend - Linear fit coeffecient, does the object get brighter or dimmer on average over time?
2  meanmedrat - ratio between the mean and the median, mean/median
3  skews - The skew of the distribution of fluxes, positive value indicates flux is skewed to values greater than the median value. A normal distribution has a skew of zero.
4  varss - variance of the flux
5  coeffvar - coeffecient of variability, the ratio of the standard deviation of the flux to the mean of the flux
6  stds - standard deviation of the flux
7  numout1s - number of flux values outside of 1-sigma deviation
8  numnegoutliers - number of fluxes values 4-sigma less than the mean
9  numposoutliers - number of flux values 4-sigma greater than the mean
10 numoutliers - total number of flux values 4-sigma away from the mean
11 kurt - kurtosis, a measure of the sharpness of the peak of the distribution of fluxes. 1/N*sum((nf-nf_mean)^4)/stds^4
12 mad - Median Absolute Difference, the median difference from the median flux
13 maxslope - the greatest positive slope between two points, dnf/dt. Uses the 99th percentile rather than the actual largest.
14 minslope - the most negative slope btw two points.
15 meanpslope - the mean of postive slopes
16 meannslope - the mean of negative slopes
17 g_asymm - ratio of mean postive slopes to the mean of negative slopes (defaults to 10 if the mean of negative slopes is 0, i.e. there are no negative slopes)
18 rough_g_asymm - ratio of the number of positive slopes to the number of negative slopes (10 if no negative slopes)
19 diff_asymm - diffence between the mean of the positive slopes and the absolute mean of the negative slopes
20 skewslope - skew of the distribution of slopes
21 meanabsslope -  mean of the absolute slopes
22 varabsslope -  variance of the absolute slopes
23 varslope - variance of the slopes
24 absmeansecder - absolute mean of the second derivative
25 num_pspikes - Number of positive spikes as defined by a positive slope 3 sigma greater than the mean positive slope.
26 num_nspikes - Number of negative spikes as defined by a negative slope 3 sigma smaller than the mean negative slope.
27 num_sdspikes # now called "num_psdspikes" - number of positive second derivative spikes
28 num_sdspikes2 #now called "num_nsdspikes" - number of negative second derivative spikes 
29 stdratio 
30 pstrend 
31 num_zcross 
32 num_pm 
33 len_nmax 
34 len_nmin 
35 mautocorrcoef 
36 ptpslopes 
37 periodicity 
38 periodicityr 
39 naiveperiod 
40 maxvars 
41 maxvarsr 
42 oeratio 
43 amp_2
44 normamp
45 mbp 
46 mid20 
47 mid35 
48 mid50 
49 mid65 
50 mid80 
51 percentamp 
52 magratio
53 sautocorrcoef 
54 autocorrcoef 
55 flatmean 
56 tflatmean 
57 roundmean 
58 troundmean 
59 roundrat 
60 flatrat


longtermtrend, 
longtermtrend=np.zeros(len(numpdc))

for i in range(len(numpdc)):
     longtermtrend[i]=np.polyfit(numtime[i], numpdc[i], 1)[0]

meanmedrat, 

"""mean and median flux and relationship"""

means=np.zeros(len(numpdc))  

for i in range(len(numpdc)):
	means[i]=np.mean(numpdc[i])

medians=np.zeros(len(numpdc))  

for i in range(len(numpdc)):
	medians[i]=np.median(numpdc[i])

meanmedrat=[means[i]/medians[i] for i in range(len(numpdc))]


skews, 
"""skew"""
skews=np.zeros(len(numpdc))  

for i in range(len(numpdc)):
	skews[i]=scipy.stats.skew(numpdc[i])


varss, 
varss=np.zeros(len(numpdc))  

for i in range(len(numpdc)):
	varss[i]=np.var(numpdc[i])


coeffvar, 
"""Coeff of variability"""

coeffvar=np.zeros(len(numpdc))  

for i in range(len(numpdc)):
	coeffvar[i]=np.std(numpdc[i])/np.mean(numpdc[i])


stds, 
"""STD"""
stds=np.zeros(len(numpdc))  

for i in range(len(numpdc)):
	stds[i]=np.std(numpdc[i])

numoutliers, numnegoutliers, numposoutliers, 
"""outliers beyond 4 sigma-decent clutering-also try one weighted according to n sigma"""

outliers=[0]*len(numpdc)
for i in range(len(numpdc)):
	outliers[i]=[numpdc[i][j] for j in range (len(numpdc[i])) if (numpdc[i][j]>means[i]+4*stds[i]) or (numpdc[i][j]<means[i]-4*stds[i])]  

numoutliers=np.zeros(len(numpdc))

for i in range(len(numpdc)):
	numoutliers[i]=len(outliers[i])

"""these outliers below for transits"""

negoutliers=[0]*len(numpdc)
for i in range(len(numpdc)):
	negoutliers[i]=[numpdc[i][j] for j in range (len(numpdc[i])) if (numpdc[i][j]<means[i]-4*stds[i])]  

numnegoutliers=np.zeros(len(numpdc))

for i in range(len(numpdc)):
	numnegoutliers[i]=len(negoutliers[i])

numposoutliers=[numoutliers[i]-numnegoutliers[i] for i in range(len(numpdc))]

numout1s, 
for i in range(len(numpdc)):
	out1std[i]=[numpdc[i][j] for j in range (len(numpdc[i])) if (numpdc[i][j]>means[i]+stds[i]) or (numpdc[i][j]<means[i]-stds[i])] 
for i in range(len(numpdc)):
	numout1s[i]=len(out1std[i])


kurt, """kurtosis"""

kurt=np.zeros(len(numpdc))

for i in range(len(numpdc)):
	kurt[i]=scipy.stats.kurtosis(numpdc[i])


mad, 
"""Median AD (MAD)"""

mad=np.zeros(len(numpdc))
for i in range(len(numpdc)):
	mad[i]=np.median([abs(numpdc[i][j]-medians[i]) for j in range(len(numpdc[i]))])

maxslope, minslope, 
slopes=[0]*(len(numpdc))
for i in range(len(numpdc)):    
	slopes[i]=[(numpdc[i][j+1]-numpdc[i][j])/(numtime[i][j+1]-numtime[i][j]) for j in range (len(numpdc[i])-1)]



"""mean slope- long term trend """
meanslope=np.zeros(len(numpdc))

for i in range(len(numpdc)):
	meanslope[i]=np.mean(slopes[i])


"""max and min slopes"""
maxslope=np.zeros(len(numpdc))
minslope=np.zeros(len(numpdc))
for i in range(len(numpdc)):
	maxslope[i]=np.percentile(slopes[i],99)
	minslope[i]=np.percentile(slopes[i],1)

meanpslope, 
	meanpslope[i]=np.mean(pslope[i])

meannslope, 
	meannslope[i]=-np.mean(nslope[i])

g_asymm, 
	g_asymm[i]=meanpslope[i]/meannslope[i]

rough_g_asymm, 
	rough_g_asymm[i]=len(pslope[i])/len(nslope[i])


diff_asymm, 
	diff_asymm[i]=meanpslope[i]-meannslope[i]

skewslope, 
"""skew slope- hope of asymmetry"""
skewslope=np.zeros(len(numpdc))  

for i in range(len(numpdc)):
	skewslope[i]=scipy.stats.skew(corrslopes[i])


varabsslope, 
varslope, 
meanabsslope, 
"""Abs slopes"""

absslopes=[0]*len(numpdc)

for i in range(len(numpdc)):
	absslopes[i]= [abs(corrslopes[i][j]) for j in range(len(corrslopes[i]))]

"""varabsslope"""

varabsslope=np.zeros(len(numpdc))
meanabsslope=np.zeros(len(numpdc))

meanabsslope=[np.var(absslopes[i]) for i in range(len(numpdc))]
varabsslope=[np.mean(absslopes[i]) for i in range(len(numpdc))]


absmeansecder, 
abssecder=[0]*(len(numpdc))

for i in range(len(numpdc)):
 	abssecder[i]=[abs((slopes[i][j]-slopes[i][j-1])/((numtime[i][j+1]-numtime[i][j])/2+(numtime[i][j]-numtime[i][j-1])/2)) for j in range (1, len(slopes[i])-1)]

absmeansecder=np.zeros(len(numpdc))
for i in range(len(numpdc)):
	absmeansecder[i]=np.mean(abssecder[i])

"""var slope"""

varslope=np.zeros(len(numpdc))

varslope=[np.var(slopes[i]) for i in range(len(slopes))]


num_pspikes, 
num_nspikes, 
num_sdspikes, 
num_sdspikes2,
stdratio, 
"""corrsecders"""
corrsecder=[0]*len(numpdc)

for i in range(len(numpdc)):
	corrsecder[i]=[(corrslopes[i][j]-corrslopes[i][j-1])/((numtime[i][j+1]-numtime[i][j])/2+(numtime[i][j]-numtime[i][j-1])/2) for j in range (1, len(corrpdc[i])-1)]

"""as regards periodicity in general,there can exist many levels"""
"""Num_spikes- you casn also isolate transits from cataclysmics using periodicity of spikes
take ratios of roundnessess or multiply them, """

stdratio=np.zeros(len(numpdc))
for i in range(len(numpdc)):
	pslopestds[i]=np.std(pslope[i])
	nslopestds[i]=np.std(nslope[i])
	sdstds[i]=np.std(corrsecder[i])
	meanstds[i]=np.mean(corrsecder[i])
	stdratio[i]=pslopestds[i]/nslopestds[i]
"""
for i in range(len(numpdc)):
	pspikes[i]=[corrslopes[i][j] for j in range(len(corrslopes[i])) if corrslopes[i][j]>=3*slopestds[i]] 
	nspikes[i]=[corrslopes[i][j] for j in range(len(corrslopes[i])) if corrslopes[i][j]<=3*slopestds[i]]
	sdspikes[i]=[corrsecder[i][j] for j in range(len(corrsecder[i])) if corrsecder[i][j]>=4*sdstds[i]] 
"""
for i in range(len(numpdc)):
	pspikes[i]=[corrslopes[i][j] for j in range(len(corrslopes[i])) if corrslopes[i][j]>=meanpslope[i]+3*pslopestds[i]] 
	nspikes[i]=[corrslopes[i][j] for j in range(len(corrslopes[i])) if corrslopes[i][j]<=meannslope[i]-3*nslopestds[i]]
	sdspikes[i]=[corrsecder[i][j] for j in range(len(corrsecder[i])) if corrsecder[i][j]>=4*sdstds[i]] 
	sdspikes2[i]=[corrsecder[i][j] for j in range(len(corrsecder[i])) if corrsecder[i][j]<=-4*sdstds[i]]

"""change around the 4 and add the min condition along with sdspike
to look for transits"""

num_pspikes=np.zeros(len(numpdc))
num_nspikes=np.zeros(len(numpdc))
num_sdspikes=np.zeros(len(numpdc))
num_sdspikes2=np.zeros(len(numpdc))

for i in range(len(numpdc)):
	num_pspikes[i]=len(pspikes[i]) 
	num_nspikes[i]=len(nspikes[i])
	num_sdspikes[i]=len(sdspikes[i])
	num_sdspikes2[i]=len(sdspikes2[i])




pstrend, """pair slope trend"""
pstrend=np.zeros(len(numpdc))
for i in range(len(numpdc)):
	pstrend[i]=len([slopes[i][j] for j in range(len(slopes[i])-1) if (slopes[i][j]>0) & (slopes[i][j+1]>0)])/len(slopes[i])


num_zcross,
"""Zero crossings- accounted for ltt, plot with gasymm"""

zcrossind=[]
for i in range(len(numpdc)):
	ltt=longtermtrend[i]
	yoff=y_offset[i]
	zcrossind.append([j for j in range(len(numpdc[i])-1) if (ltt*numtime[i][j+1]+ yoff-numpdc[i][j+1])*(ltt*numtime[i][j]+yoff-numpdc[i][j])<0])


num_zcross=np.zeros(len(numpdc))

for i in range(len(numpdc)):
	num_zcross[i]=len(zcrossind[i])
 
num_pm, 
"""pm"""
plusminus=[0]*len(numpdc)


for i in range(len(numpdc)):
	plusminus[i]=[j for j in range(1,len(slopes[i])) if (slopes[i][j]<0)&(slopes[i][j-1]>0)]

num_pm=np.zeros(len(numpdc))  
num_pm=[len(plusminus[i]) for i in range(len(numpdc))] 


len_nmax
"""naive maxima and corresponding time values you can do it with 5 or 10 or something else, 1 or two largest"""

naivemaxes=[0]*len(numpdc)
nmax_times=[0]*len(numpdc)
maxinds=[0]*len(numpdc)
maxerr=[0]*len(numpdc)
for i in range(len(numpdc)):
	naivemaxes[i]=[corrpdc[i][j] for j in range (len(numpdc[i])) if corrpdc[i][j] in heapq.nlargest(1, corrpdc[i][max(j-10,0):min(j+10, len(numpdc[i])-1): 1])]
	nmax_times[i]=[numtime[i][j] for j in range (len(numpdc[i])) if corrpdc[i][j] in heapq.nlargest(1, corrpdc[i][max(j-10,0):min(j+10, len(numpdc[i])-1): 1])]
	maxinds[i]=[j for j in range (len(numpdc[i])) if corrpdc[i][j] in heapq.nlargest(1, corrpdc[i][max(j-10,0):min(j+10, len(numpdc[i])-1): 1])]
	maxerr[i]=[err[i][j] for j in maxinds[i]]

"""numbers of naive maxima"""

len_nmax=np.zeros(len(numpdc))

for i in range(len(numpdc)):
	len_nmax[i]=len(naivemaxes[i])

len_nmin - """numbers of naive minima"""

len_nmin=np.zeros(len(numpdc))

for i in range(len(numpdc)):
	len_nmin[i]=len(naivemins[i])

mautocorrcoef - """Auto-correlation function of one maximum to next-good clustering"""

autopdcmax=[0]*len(numpdc)
for i in range(len(numpdc)):
	autopdcmax[i]=[naivemaxes[i][j+1] for j in range(len(naivemaxes[i])-1)]

mautocovs=np.zeros(len(numpdc))
mautocorrcoef=np.zeros(len(numpdc))

for i in range(len(numpdc)):
	mautocorrcoef[i]=np.corrcoef(naivemaxes[i][:-1:], autopdcmax[i])[0][1]
	mautocovs[i]=np.cov(naivemaxes[i][:-1:],autopdcmax[i])[0][1]
 

ptpslopes - """peak to peak slopes"""
ptpslopes=np.zeros(len(numpdc))
ppslopes=[0]*len(numpdc)
for i in range(len(numpdc)):
	ppslopes[i]=[abs((naivemaxes[i][j+1]-naivemaxes[i][j])/(nmax_times[i][j+1]-nmax_times[i][j])) for j in range(len(naivemaxes[i])-1)]

for i in range(len(numpdc)):
	ptpslopes[i]=np.mean(ppslopes[i])

periodicity, periodicityr, naiveperiod
"""Variation coefficient of time difference between successive maxima- periodicity?"""

maxdiff=[0]*(len(numpdc))
for i in range(len(numpdc)):
	maxdiff[i]=[nmax_times[i][j+1]-nmax_times[i][j] for j in range(len(naivemaxes[i])-1)]

periodicity=np.zeros(len(numpdc))
periodicityr=np.zeros(len(numpdc))
for i in range(len(numpdc)):
	periodicity[i]=np.std(maxdiff[i])/np.mean(maxdiff[i])
	periodicityr[i]=np.sum(abs(maxdiff[i]-np.mean(maxdiff[i])))/np.mean(maxdiff[i])
naiveperiod=np.zeros(len(numpdc))

for i in range(len(numpdc)):
	naiveperiod[i]=np.mean(maxdiff[i])

 
maxvars & maxvarsr - """variation coefficient of the maxima"""
maxvars=np.zeros(len(numpdc))
maxvarsr=np.zeros(len(numpdc))
for i in range(len(numpdc)):
	maxvars[i]=np.std(naivemaxes[i])/np.mean(naivemaxes[i])

for i in range(len(numpdc)):
	maxvars[i]=np.std(naivemaxes[i])/np.mean(naivemaxes[i])
	maxvarsr[i]=np.sum(abs(naivemaxes[i]-np.mean(naivemaxes[i])))/np.mean(naivemaxes[i])


oeratio, 
omin=[0]*len(numpdc)
emin=[0]*len(numpdc)
meanomin=np.zeros(len(numpdc))
meanemin=np.zeros(len(numpdc))
for i in range(len(numpdc)):
	emin[i]=[naivemins[i][j] for j in range(len(naivemins[i])) if j%2==0]
	omin[i]=[naivemins[i][j] for j in range(len(naivemins[i])) if j%2!=0]
"""local secder dip"""
for i in range(len(numpdc)):
	meanemin[i]=np.mean(emin[i])
	meanomin[i]=np.mean(omin[i])
"""plt.scatter(meanomin, meanemin)"""
oeratio=np.zeros(len(numpdc))
for i in range(len(numpdc)):
	oeratio[i]=meanomin[i]/meanemin[i]



amp_2 & normamp:

amp_2=np.zeros(len(numpdc))
amp =np.zeros(len(numpdc))

for i in range(len(numpdc)):
	amp[i]=np.percentile(numpdc[i],99)-np.percentile(numpdc[i],1)
	amp_2[i]=np.percentile(corrpdc[i],99)-np.percentile(corrpdc[i],1)

normnaiveamp=np.zeros(len(numpdc))
normamp=np.zeros(len(numpdc))

for i in range(len(numpdc)):
	normnaiveamp[i]=naive_amp_2[i]/np.mean(numpdc[i])
	normamp[i]=amp_2[i]/np.mean(numpdc[i])



mbp - Median Buffer Percentile

for i in range(len(numpdc)):
	mbp[i]=len([numpdc[i][j] for j in range(len(numpdc[i])) if (numpdc[i][j]<(medians[i]+0.1*amp_2[i])) & (numpdc[i][j]>(medians[i]-0.1*amp_2[i]))])/len(numpdc[i])


mid20, 
	f4060[i]=np.percentile(numpdc[i], 60)-np.percentile(numpdc[i], 40)
	f595[i]=np.percentile(numpdc[i],95)-np.percentile(numpdc[i],5)
	mid20[i]=f4060[i]/f595[i]

mid35, 
	f595[i]=np.percentile(numpdc[i],95)-np.percentile(numpdc[i],5)
	f3267[i]=np.percentile(numpdc[i], 67)-np.percentile(numpdc[i], 32)
	mid35[i]=f3267[i]/f595[i]

mid50, 
	f2575[i]=np.percentile(numpdc[i], 75)-np.percentile(numpdc[i], 25)
	f595[i]=np.percentile(numpdc[i],95)-np.percentile(numpdc[i],5)
	mid50[i]=f2575[i]/f595[i]

mid65, 
	f1782[i]=np.percentile(numpdc[i], 82)-np.percentile(numpdc[i], 17)
	f595[i]=np.percentile(numpdc[i],95)-np.percentile(numpdc[i],5)
	mid65[i]=f1782[i]/f595[i]

mid80, 
	f1090[i]=np.percentile(numpdc[i],90)-np.percentile(numpdc[i],10)	
	f595[i]=np.percentile(numpdc[i],95)-np.percentile(numpdc[i],5)
	mid80[i]=f1090[i]/f595[i]


percentamp, 
for i in range(len(numpdc)):
	percentamp[i]=max([(corrpdc[i][j]-medians[i])/medians[i] for j in range(len(corrpdc[i]))])

magratio, 
magratio=[(max(numpdc[i])-medians[i])/amp[i] for i in range(len(numpdc))]

sautocorrcoef, 
sautopdc=[0]*len(slopes)
for i in range(len(slopes)):
	sautopdc[i]=[slopes[i][j+1] for j in range(len(slopes[i])-1)]

sautocovs=np.zeros(len(slopes))
for i in range(len(slopes)):
	sautocorrcoef[i]=np.corrcoef(slopes[i][:-1:], sautopdc[i])[0][1]
	sautocovs[i]=np.cov(slopes[i][:-1:],sautopdc[i])[0][1]

autocorrcoef, 
autopdc=[0]*len(numpdc)
for i in range(len(numpdc)):
	autopdc[i]=[numpdc[i][j+1] for j in range(len(numpdc[i])-1)]

autocovs=np.zeros(len(numpdc))
autocorrcoef=np.zeros(len(numpdc))

for i in range(len(numpdc)):
	autocorrcoef[i]=np.corrcoef(numpdc[i][:-1:], autopdc[i])[0][1]
	autocovs[i]=np.cov(numpdc[i][:-1:],autopdc[i])[0][1]

flatmean, 
for i in range(len(numpdc)):
	flatmean[i]=np.nansum(flatness[i])/len(flatness[i])

tflatmean, 
for i in range(len(numpdc)):
	tflatmean[i]=np.nansum(tflatness[i])/len(tflatness[i])

roundmean, 
for i in range(len(numpdc)):
	roundmean[i]=np.nansum(roundness[i])/len(roundness[i])


troundmean, 
for i in range(len(numpdc)):
	troundmean[i]=np.nansum(troundness[i])/len(troundness[i])

roundrat, 
for i in range(len(numpdc)):
	roundrat[i]=roundmean[i]/troundmean[i]

flatrat
for i in range(len(numpdc)):
	flatrat[i]=flatmean[i]/tflatmean[i]


